{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHILOGjOQbsQ"
   },
   "source": [
    "# **Pytorch Tutorial 2**\n",
    "Video: https://youtu.be/VbqNn20FoHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "C1zA7GupxdJv"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Eqj90EkWbWx"
   },
   "source": [
    "**1. Pytorch Documentation Explanation with torch.max**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCXOg-iSQuk7",
    "outputId": "957c8de4-d306-4533-f69e-fe285a6409df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1033,  0.3581,  0.5794, -0.2775, -0.7330],\n",
      "        [ 0.0868, -0.6829, -0.1523,  1.0311, -0.0720],\n",
      "        [-0.0827, -0.6847, -0.5167, -0.2263, -0.7899],\n",
      "        [-0.0179, -0.6131, -0.8498,  0.4497,  1.0002]])\n",
      "tensor([[-0.0606,  1.3950, -0.4186, -0.1318,  1.3777],\n",
      "        [-0.3304, -1.4855, -0.6949,  0.0357, -1.2230],\n",
      "        [-0.3610, -1.6722, -0.0543,  0.3228, -0.4858],\n",
      "        [ 1.3305,  0.3159, -0.8881, -0.1892, -0.5504]])\n",
      "tensor([[ 0.8719,  0.3279,  1.9488,  2.0328, -0.2449],\n",
      "        [ 0.4915,  1.9903, -2.0807, -1.1485,  0.5839],\n",
      "        [-1.2320,  1.7203,  2.5943,  1.5003, -0.5446],\n",
      "        [ 1.4770, -0.1436,  1.8054, -0.9330,  0.2279]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "y = torch.randn(4,5)\n",
    "z = torch.randn(4,5)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEqa9GFoWF78",
    "outputId": "4f38ae34-5b7e-4b12-e03a-ed6bb2602f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0311)\n"
     ]
    }
   ],
   "source": [
    "# 1. max of entire tensor (torch.max(input) → Tensor)\n",
    "m = torch.max(x)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wffThGDyWKxJ",
    "outputId": "eba5d365-75b5-468d-b088-b72b3c0421a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0868, 0.3581, 0.5794, 1.0311, 1.0002])\n",
      "tensor([1, 0, 0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. max along a dimension (torch.max(input, dim, keepdim=False, *, out=None) → (Tensor, LongTensor))\n",
    "m, idx = torch.max(x,0)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKDQW3tIXKg-",
    "outputId": "49cd8a9b-9e9c-4cb6-c8cb-9ae122e845ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0868, 0.3581, 0.5794, 1.0311, 1.0002])\n",
      "tensor([1, 0, 0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2-2\n",
    "m, idx = torch.max(input=x,dim=0)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QZ6WRLyX3De",
    "outputId": "5f9dc0bd-a53b-4ea2-9364-5e253c18f0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0868, 0.3581, 0.5794, 1.0311, 1.0002])\n",
      "tensor([1, 0, 0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2-3\n",
    "m, idx = torch.max(x,0,False)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqGuctkKbUEn",
    "outputId": "502eb14b-8253-4e69-e12f-90a37d2d3068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0868, 0.3581, 0.5794, 1.0311, 1.0002]])\n",
      "tensor([[1, 0, 0, 1, 3]])\n"
     ]
    }
   ],
   "source": [
    "# 2-4\n",
    "m, idx = torch.max(x,dim=0,keepdim=True)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OMzxuMlZPIu",
    "outputId": "e287ebbf-cb95-4ef8-bc74-d3436e4316b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0868, 0.3581, 0.5794, 1.0311, 1.0002])\n",
      "tensor([1, 0, 0, 1, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86406/1447715753.py:3: UserWarning: An output with one or more elements was resized since it had shape [1, 5], which does not match the required output shape [5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/aten/src/ATen/native/Resize.cpp:28.)\n",
      "  torch.max(x,0,False,out=p)\n"
     ]
    }
   ],
   "source": [
    "# 2-5\n",
    "p = (m,idx)\n",
    "torch.max(x,0,False,out=p)\n",
    "print(p[0])\n",
    "print(p[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "uhd4TqGTbD2c",
    "outputId": "be65fed5-2a38-40e7-f26e-9edf30b97654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0868, 0.3581, 0.5794, 1.0311, 1.0002])\n",
      "tensor([1, 0, 0, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2-6\n",
    "p = (m, idx)\n",
    "torch.max(x, 0, False, out=p)\n",
    "print(p[0])\n",
    "print(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "wbxjUSOXxN0n",
    "outputId": "aaff3239-eafe-4c31-e3d3-5bc343c88397"
   },
   "outputs": [],
   "source": [
    "# 2-7\n",
    "m, idx = torch.max(x, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMwhGLlGWYaR",
    "outputId": "f712e674-21f4-45de-958c-fb0b7e76dfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0606,  1.3950,  0.5794, -0.1318,  1.3777],\n",
      "        [ 0.0868, -0.6829, -0.1523,  1.0311, -0.0720],\n",
      "        [-0.0827, -0.6847, -0.0543,  0.3228, -0.4858],\n",
      "        [ 1.3305,  0.3159, -0.8498,  0.4497,  1.0002]])\n"
     ]
    }
   ],
   "source": [
    "# 3. max(choose max) operators on two tensors (torch.max(input, other, *, out=None) → Tensor)\n",
    "t = torch.max(x,y)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFxRKu2Dedwb"
   },
   "source": [
    "**2. Common errors**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMcRyMxGwhul"
   },
   "source": [
    "The following code blocks show some common errors while using the torch library. First, execute the code with error, and then execute the next code block to fix the error. You need to change the runtime to GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "eX-kKdi6ynFf"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "-muJ4KKreoP2",
    "outputId": "a663e92d-63f5-4a1a-fea8-45badaf17020"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# 1. different device error\n",
    "model = torch.nn.Linear(5,1).to(\"cuda:0\")\n",
    "x = torch.randn(5).to(\"cpu\")\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a54PqxJLe9-c",
    "outputId": "59d31dd0-bb14-4741-b274-45960e884fd1"
   },
   "outputs": [],
   "source": [
    "# 1. different device error (fixed)\n",
    "x = torch.randn(5).to(\"cuda:0\")\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "n7OHtZwbi7Qw",
    "outputId": "4afb4e0c-6477-496c-fe57-edd8452ee3cd"
   },
   "outputs": [],
   "source": [
    "# 2. mismatched dimensions error 1\n",
    "x = torch.randn(4,5)\n",
    "y = torch.randn(5,4)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVynzvrskFCD",
    "outputId": "fd2f5918-82e9-4376-bc2e-38a00c2a3169"
   },
   "outputs": [],
   "source": [
    "# 2. mismatched dimensions error 1 (fixed by transpose)\n",
    "y = y.transpose(0,1)\n",
    "z = x + y\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "Hgzgb9gJANod",
    "outputId": "15e70cb4-94ec-4b93-e9d0-cd56a01091a9"
   },
   "outputs": [],
   "source": [
    "# 3. cuda out of memory error\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18().to(\"cuda:0\") # Neural Networks for Image Recognition\n",
    "data = torch.randn(2048,3,244,244) # Create fake data (512 images)\n",
    "out = resnet18(data.to(\"cuda:0\")) # Use Data as Input and Feed to Model\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPksKnB_w343",
    "outputId": "2566b695-61dd-4ade-b472-0957db36a94b"
   },
   "outputs": [],
   "source": [
    "# 3. cuda out of memory error (fixed, but it might take some time to execute)\n",
    "for d in data:\n",
    "  out = resnet18(d.to(\"cuda:0\").unsqueeze(0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "vqszlxEE0Bk0",
    "outputId": "b5e17e21-80dc-461c-a31e-c5eabccf1431"
   },
   "outputs": [],
   "source": [
    "# 4. mismatched tensor type\n",
    "import torch.nn as nn\n",
    "L = nn.CrossEntropyLoss()\n",
    "outs = torch.randn(5,5)\n",
    "labels = torch.Tensor([1,2,3,4,0])\n",
    "lossval = L(outs,labels) # Calculate CrossEntropyLoss between outs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZwgwup_1dgS",
    "outputId": "cdc614fc-b533-4f4d-ce39-56f55a0d942c"
   },
   "outputs": [],
   "source": [
    "# 4. mismatched tensor type (fixed)\n",
    "labels = labels.long()\n",
    "lossval = L(outs,labels)\n",
    "print(lossval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSuNdA8F06dK"
   },
   "source": [
    "**3. More on dataset and dataloader**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in84z_xu1rE6"
   },
   "source": [
    "A dataset is a cluster of data in a organized way. A dataloader is a loader which can iterate through the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34zfh-c22Qqs"
   },
   "source": [
    "Let a dataset be the English alphabets \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TaiHofty1qKA"
   },
   "outputs": [],
   "source": [
    "dataset = \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0jwhVa12h3a"
   },
   "source": [
    "A simple dataloader could be implemented with the python code \"for\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWC5Wwbv2egy",
    "outputId": "fb5ca312-ccde-476b-9ee9-0c3d9d0ce9ed"
   },
   "outputs": [],
   "source": [
    "for datapoint in dataset:\n",
    "  print(datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n33VKzkG2y2U"
   },
   "source": [
    "When using the dataloader, we often like to shuffle the data. This is where torch.utils.data.DataLoader comes in handy. If each data is an index (0,1,2...) from the view of torch.utils.data.DataLoader, shuffling can simply be done by shuffling an index array. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MXUUKQ65APf"
   },
   "source": [
    "torch.utils.data.DataLoader will need two imformation to fulfill its role. First, it needs to know the length of the data. Second, once torch.utils.data.DataLoader outputs the index of the shuffling results, the dataset needs to return the corresponding data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV5txsjK5j4j"
   },
   "source": [
    "Therefore, torch.utils.data.Dataset provides the imformation by two functions, `__len__()` and `__getitem__()` to support torch.utils.data.Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0IEkemJ5ajD",
    "outputId": "0f868f2f-40c5-46ea-ec85-e3ec6d05c2f2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data \n",
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "  \n",
    "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
    "    return self.data[idx]\n",
    "  \n",
    "  def __len__(self): # What is the length of the dataset\n",
    "    return len(self.data)\n",
    "\n",
    "dataset1 = ExampleDataset() # create the dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "                        dataset = dataset1, \n",
    "                        shuffle = True, \n",
    "                        batch_size = 1\n",
    "              )\n",
    "for datapoint in dataloader:\n",
    "  print(datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTt-ZTid9S2n"
   },
   "source": [
    "A simple data augmentation technique can be done by changing the code in `__len__()` and `__getitem__()`. Suppose we want to double the length of the dataset by adding in the uppercase letters, using only the lowercase dataset, you can change the dataset to the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Wn3BA2j-NXl",
    "outputId": "09f8509f-f53f-4ebd-aedd-7691fcd51ec4"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data \n",
    "class ExampleDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "  \n",
    "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
    "    if idx >= len(self.data): # if the index >= 26, return upper case letter\n",
    "      return self.data[idx%26].upper()\n",
    "    else: # if the index < 26, return lower case, return lower case letter\n",
    "      return self.data[idx]\n",
    "  \n",
    "  def __len__(self): # What is the length of the dataset\n",
    "    return 2 * len(self.data) # The length is now twice as large\n",
    "\n",
    "dataset1 = ExampleDataset() # create the dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset = dataset1,shuffle = True,batch_size = 1)\n",
    "for datapoint in dataloader:\n",
    "  print(datapoint)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch Tutorial Colab example",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
